{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11623010,"sourceType":"datasetVersion","datasetId":7291586},{"sourceId":11831574,"sourceType":"datasetVersion","datasetId":7432894}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installations and Importing","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers accelerate bert-score\n\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom PIL import Image\nimport torch\nimport pandas as pd\nfrom tqdm import tqdm\nfrom bert_score import score\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:40:24.356329Z","iopub.execute_input":"2025-05-16T13:40:24.356934Z","iopub.status.idle":"2025-05-16T13:42:06.919336Z","shell.execute_reply.started":"2025-05-16T13:40:24.356910Z","shell.execute_reply":"2025-05-16T13:42:06.918505Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"2025-05-16 13:41:55.245303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747402915.445335      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747402915.500830      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Load processor and model","metadata":{}},{"cell_type":"code","source":"\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:42:06.920419Z","iopub.execute_input":"2025-05-16T13:42:06.920942Z","iopub.status.idle":"2025-05-16T13:42:17.062905Z","shell.execute_reply.started":"2025-05-16T13:42:06.920919Z","shell.execute_reply":"2025-05-16T13:42:17.062170Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b973e3d674f0497cb836ca55a4f3fada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be9a625371143e6be54354228d90209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63ead6bd51e7451c81aac5488c4e2190"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df047ce3a6e444e8b816784f218612b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534c9a14f562430b8ece3ec0afd3a444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd44d01f2f44755a2b543f1620bcf3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf6d2866da64f0da7498d06bb9501e0"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"BlipForQuestionAnswering(\n  (vision_model): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_encoder): BlipTextModel(\n    (embeddings): BlipTextEmbeddings(\n      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): BlipTextEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BlipTextLayer(\n          (attention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (crossattention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): BlipTextIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BlipTextOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (text_decoder): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Load dataset (20000,5000, 500 sample for comparison)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/dataforvr/complete_updated.csv\")  # <-- Replace with actual path\ndf = df.dropna(subset=[\"path\", \"question\", \"answer\"])\ndf_5k = df.sample(n=5000, random_state=42).reset_index(drop=True)\ndf_500=df.sample(n=500,random_state=42).reset_index(drop=True)\ndf_20k=df.sample(n=20000,random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:42:17.063848Z","iopub.execute_input":"2025-05-16T13:42:17.064162Z","iopub.status.idle":"2025-05-16T13:42:18.493011Z","shell.execute_reply.started":"2025-05-16T13:42:17.064135Z","shell.execute_reply":"2025-05-16T13:42:18.492062Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"##  Inference Function","metadata":{}},{"cell_type":"code","source":"def get_prediction(image_path, question):\n    image = Image.open(image_path).convert('RGB')\n    inputs = processor(image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n    output = model.generate(**inputs, max_new_tokens=5)\n    pred = processor.decode(output[0], skip_special_tokens=True)\n    return pred.strip().lower().split()[0]  # one-word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:42:18.494722Z","iopub.execute_input":"2025-05-16T13:42:18.494955Z","iopub.status.idle":"2025-05-16T13:42:18.499501Z","shell.execute_reply.started":"2025-05-16T13:42:18.494937Z","shell.execute_reply":"2025-05-16T13:42:18.498769Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Inference Loop","metadata":{}},{"cell_type":"code","source":"def run_vqa(df_input, save_path):\n    results = []\n    for _, row in tqdm(df_input.iterrows(), total=len(df_input)):\n        try:\n            image_path = \"/kaggle/input/abo-small/vr_project/abo-images-small/images/small/\" + row[\"path\"]\n            question = row[\"question\"]\n            ground_truth = row[\"answer\"].strip().lower()\n            prediction = get_prediction(image_path, question)\n\n            is_correct = (prediction == ground_truth)\n            token_f1 = 1.0 if is_correct else 0.0\n\n            results.append({\n                \"image_id\": row[\"image_id\"],\n                \"image\": row[\"path\"],\n                \"question\": question,\n                \"ground_truth\": ground_truth,\n                \"prediction\": prediction,\n                \"correct\": is_correct,\n                \"token_f1\": token_f1\n            })\n\n        except Exception as e:\n            results.append({\n                \"image_id\": row[\"image_id\"],\n                \"image\": row[\"path\"],\n                \"question\": row[\"question\"],\n                \"ground_truth\": row[\"answer\"],\n                \"prediction\": \"error\",\n                \"correct\": False,\n                \"token_f1\": 0.0\n            })\n\n    results_df = pd.DataFrame(results)\n\n    # BERTScore\n    P, R, F1 = score(results_df[\"prediction\"].tolist(), results_df[\"ground_truth\"].tolist(), lang=\"en\", verbose=True)\n    results_df[\"bertscore_f1\"] = F1.tolist()\n\n    # Save to CSV\n    results_df.to_csv(save_path, index=False)\n    return results_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:42:18.500326Z","iopub.execute_input":"2025-05-16T13:42:18.500635Z","iopub.status.idle":"2025-05-16T13:42:18.516360Z","shell.execute_reply.started":"2025-05-16T13:42:18.500618Z","shell.execute_reply":"2025-05-16T13:42:18.515749Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Run on all sets","metadata":{}},{"cell_type":"code","source":"results_5k = run_vqa(df_5k, \"vqa_5k_baseline.csv\")\nresults_500 = run_vqa(df_500, \"vqa_500_baseline.csv\")\nresults_20k = run_vqa(df_20k, \"vqa_20k_baseline.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T13:42:18.517261Z","iopub.execute_input":"2025-05-16T13:42:18.517579Z","iopub.status.idle":"2025-05-16T14:17:55.370353Z","shell.execute_reply.started":"2025-05-16T13:42:18.517553Z","shell.execute_reply":"2025-05-16T14:17:55.369678Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5000/5000 [07:07<00:00, 11.71it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d5270e995a441fbce6b8219329bbe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0ce6d7d0624e56bc2dd40f48b1cef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"905061fbcdce4ca0bae9dae18c8d9266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf2de96cbb04dd3a9a590f855c4eba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8189bcdad9c64e9cbeb16bf044481104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"746fcc4664774dc3b584b5486908bdf9"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7305b285f4824bcbb3dbaf1181f55a98"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19fc6ff2487c4888850b2e42f6d5b9a7"}},"metadata":{}},{"name":"stdout","text":"done in 2.14 seconds, 2341.62 sentences/sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [00:39<00:00, 12.57it/s]\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a4416a12b6408c81ce286a484a43e1"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbfcae3cb4f047c383de5b817d1b6a78"}},"metadata":{}},{"name":"stdout","text":"done in 0.40 seconds, 1243.91 sentences/sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [27:29<00:00, 12.12it/s]\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d7362c61ba431eaf9dba1957ba0497"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b410ab5b06804eaea54d8ea9e96f9f38"}},"metadata":{}},{"name":"stdout","text":"done in 5.29 seconds, 3783.26 sentences/sec\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def summarize(df, label):\n    print(f\"--- {label} ---\")\n    acc = df[\"correct\"].mean()\n    f1_token = df[\"token_f1\"].mean()\n    f1_bert = df[\"bertscore_f1\"].mean()\n    print(f\"Accuracy:     {acc:.4f}\")\n    print(f\"Token-F1:     {f1_token:.4f}\")\n    print(f\"BERTScore-F1: {f1_bert:.4f}\")\n\nsummarize(results_5k, \"Full 5k\")\nsummarize(results_500, \"Subsample 500\")\nsummarize(results_20k, \"Full 20k\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:17:55.371521Z","iopub.execute_input":"2025-05-16T14:17:55.371949Z","iopub.status.idle":"2025-05-16T14:17:55.378878Z","shell.execute_reply.started":"2025-05-16T14:17:55.371928Z","shell.execute_reply":"2025-05-16T14:17:55.378318Z"}},"outputs":[{"name":"stdout","text":"--- Full 5k ---\nAccuracy:     0.3496\nToken-F1:     0.3496\nBERTScore-F1: 0.9592\n--- Subsample 500 ---\nAccuracy:     0.3260\nToken-F1:     0.3260\nBERTScore-F1: 0.9596\n--- Full 20k ---\nAccuracy:     0.3525\nToken-F1:     0.3525\nBERTScore-F1: 0.9611\n","output_type":"stream"}],"execution_count":8}]}