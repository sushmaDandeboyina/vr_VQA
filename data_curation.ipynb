{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "6vi7V2ExV61X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:32:55.690001Z",
          "iopub.status.busy": "2025-05-14T12:32:55.689389Z",
          "iopub.status.idle": "2025-05-14T12:32:55.954662Z",
          "shell.execute_reply": "2025-05-14T12:32:55.954058Z",
          "shell.execute_reply.started": "2025-05-14T12:32:55.689977Z"
        },
        "id": "tlQBdbAgV61a",
        "outputId": "62ce5c0f-cd5f-4c89-bfa2-c4297a2c17d3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['metadata', 'abo-images-small']\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"shaikmdirfan/images\")\n",
        "\n",
        "print(os.listdir(dataset_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:32:58.297457Z",
          "iopub.status.busy": "2025-05-14T12:32:58.297199Z",
          "iopub.status.idle": "2025-05-14T12:33:01.343265Z",
          "shell.execute_reply": "2025-05-14T12:33:01.342371Z",
          "shell.execute_reply.started": "2025-05-14T12:32:58.297437Z"
        },
        "id": "OC2P5F34V61c",
        "outputId": "b3515767-c2ea-463e-dc1a-5a3d76e97416",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai\n",
        "\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:03.681523Z",
          "iopub.status.busy": "2025-05-14T12:33:03.681263Z",
          "iopub.status.idle": "2025-05-14T12:33:04.171020Z",
          "shell.execute_reply": "2025-05-14T12:33:04.170357Z",
          "shell.execute_reply.started": "2025-05-14T12:33:03.681503Z"
        },
        "id": "n-kIPr37V61e",
        "outputId": "14c133c2-bd44-483a-a9b4-cd25d74aa51d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(398212, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>010-mllS7JL</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>14/14fe8812.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01dkn0Gyx0L</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>da/daab0cad.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01sUPg0387L</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>d2/d2daaae9.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1168jc-5r1L</td>\n",
              "      <td>186</td>\n",
              "      <td>186</td>\n",
              "      <td>3a/3a4e88e6.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11RUV5Fs65L</td>\n",
              "      <td>30</td>\n",
              "      <td>500</td>\n",
              "      <td>d9/d91ab9cf.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_id  height  width             path\n",
              "0  010-mllS7JL     106    106  14/14fe8812.jpg\n",
              "1  01dkn0Gyx0L     122    122  da/daab0cad.jpg\n",
              "2  01sUPg0387L     111    111  d2/d2daaae9.jpg\n",
              "3  1168jc-5r1L     186    186  3a/3a4e88e6.jpg\n",
              "4  11RUV5Fs65L      30    500  d9/d91ab9cf.jpg"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata_path = os.path.join(dataset_dir, 'abo-images-small/images/metadata/images.csv')\n",
        "df = pd.read_csv(metadata_path)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:08.152602Z",
          "iopub.status.busy": "2025-05-14T12:33:08.152316Z",
          "iopub.status.idle": "2025-05-14T12:33:13.696914Z",
          "shell.execute_reply": "2025-05-14T12:33:13.696005Z",
          "shell.execute_reply.started": "2025-05-14T12:33:08.152572Z"
        },
        "id": "CEaStjSrV61g",
        "outputId": "feca3eeb-4154-464f-e255-bb9711f8ea7f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 147702 metadata entries!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "listings_dir = os.path.join(dataset_dir, '/kaggle/input/vr-mini2/bhavya_preprocessing/Jsonfiles')\n",
        "\n",
        "metadata_records = []\n",
        "\n",
        "for file in tqdm(os.listdir(listings_dir)):\n",
        "    if file.endswith('.json'):\n",
        "\n",
        "        file_path = os.path.join(listings_dir, file)\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        data = json.loads(line)\n",
        "                        metadata_records.append(data)\n",
        "                    except json.JSONDecodeError as e:\n",
        "                        print(f\"Skipping line due to error: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(metadata_records)} metadata entries!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-14T12:24:23.413160Z",
          "iopub.status.idle": "2025-05-14T12:24:23.413370Z",
          "shell.execute_reply": "2025-05-14T12:24:23.413279Z",
          "shell.execute_reply.started": "2025-05-14T12:24:23.413269Z"
        },
        "id": "xMSxtWRkV61i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(metadata_records[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:17.505607Z",
          "iopub.status.busy": "2025-05-14T12:33:17.504966Z",
          "iopub.status.idle": "2025-05-14T12:33:18.144150Z",
          "shell.execute_reply": "2025-05-14T12:33:18.143550Z",
          "shell.execute_reply.started": "2025-05-14T12:33:17.505583Z"
        },
        "id": "M4PHWbcIV61j",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "metadata_dict = {}\n",
        "\n",
        "for record in metadata_records:\n",
        "    main_id = record.get('main_image_id')\n",
        "\n",
        "    other_ids = record.get('other_image_id', [])\n",
        "\n",
        "    if main_id:\n",
        "        metadata_dict[main_id] = record\n",
        "\n",
        "    for other_id in other_ids:\n",
        "        metadata_dict[other_id] = record\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-14T04:21:24.907456Z",
          "iopub.status.idle": "2025-05-14T04:21:24.907664Z",
          "shell.execute_reply": "2025-05-14T04:21:24.907575Z",
          "shell.execute_reply.started": "2025-05-14T04:21:24.907565Z"
        },
        "id": "_7dblVlQV61k",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"metadata_output.json\", \"w\") as f:\n",
        "    json.dump(metadata_dict, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-14T12:24:23.411810Z",
          "iopub.status.idle": "2025-05-14T12:24:23.412164Z",
          "shell.execute_reply": "2025-05-14T12:24:23.412008Z",
          "shell.execute_reply.started": "2025-05-14T12:24:23.411990Z"
        },
        "id": "fdQx8cXsV61l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T11:44:49.701907Z",
          "iopub.status.busy": "2025-05-14T11:44:49.701429Z",
          "iopub.status.idle": "2025-05-14T11:44:49.705910Z",
          "shell.execute_reply": "2025-05-14T11:44:49.705122Z",
          "shell.execute_reply.started": "2025-05-14T11:44:49.701883Z"
        },
        "id": "6aUyUgN0V61m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(\"progress.txt\", \"w\") as f:\n",
        "    f.write(\"160000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa742AnV61m"
      },
      "source": [
        "# Curating starts here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Define the Batch VQA Generation Function for 10 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:24.532508Z",
          "iopub.status.busy": "2025-05-14T12:33:24.532257Z",
          "iopub.status.idle": "2025-05-14T12:33:24.555289Z",
          "shell.execute_reply": "2025-05-14T12:33:24.554629Z",
          "shell.execute_reply.started": "2025-05-14T12:33:24.532491Z"
        },
        "id": "mqokglwjV61q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_vqa_batch(images, metadata_texts, api_key, temperature):\n",
        "    \"\"\"\n",
        "    Generates question-answer pairs for 10 e-commerce products in one API call.\n",
        "\n",
        "    Args:\n",
        "        images: List of 10 PIL Image objeccts.\n",
        "        metadata_texts: List of 10 strings, each containing metadata for a product.\n",
        "        api_key: Your Gemini API key.\n",
        "        temperature: Temperature parameter for generation.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries for each product with keys:\n",
        "            \"product\": The product number (1 to 10).\n",
        "            \"question\": The generated question.\n",
        "            \"answer\": The generated answer.\n",
        "        In case of an error, if the error message indicates a 429 rate-limit,\n",
        "        the error is re-raised.\n",
        "    \"\"\"\n",
        "    assert len(images) == 10 and len(metadata_texts) == 10, \"Exactly 10 images and metadata items required.\"\n",
        "\n",
        "    batch_prompt = \"\"\"\n",
        "You are a question-answer pair generator specializing in vision-language alignment for e-commerce products.\n",
        "\n",
        "Given the image and detailed metadata of each product, generate *one concise and context-rich question* per product.\n",
        "**Important:**\n",
        "- Do not focus solely on color. Ensure the questions cover different aspects such as product brand, shape, material, design, size, or functionality.\n",
        "- The question must require visual input and be directly related to attributes visible in both the image and metadata.\n",
        "- Avoid yes/no questions; answers must be a single, fact-based word.\n",
        "\n",
        "### Output format:\n",
        "product 1:\n",
        "Question: <Your question here>\n",
        "Answer: <Short descriptive answer>\n",
        "\n",
        "product 2:\n",
        "Question: <Your question here>\n",
        "Answer: <Short descriptive answer>\n",
        "\n",
        "...\n",
        "product 10:\n",
        "Question: <Your question here>\n",
        "Answer: <Short descriptive answer>\n",
        "\n",
        "Do not include any extra commentary.\n",
        "    \"\"\"\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "    generation_config = genai.types.GenerationConfig(temperature=temperature, top_k=2)\n",
        "\n",
        "    parts = [batch_prompt]\n",
        "    for i in range(10):\n",
        "        parts.append(f\"Product {i+1} metadata:\\n{metadata_texts[i]}\")\n",
        "        parts.append(images[i])\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(parts, generation_config=generation_config)\n",
        "        qa_pairs_text = response.text\n",
        "\n",
        "        pattern = re.compile(r'product\\s*(\\d+):\\s*Question:\\s*(.+?)\\s*Answer:\\s*(\\S+)',\n",
        "                             re.DOTALL | re.IGNORECASE)\n",
        "        matches = pattern.findall(qa_pairs_text)\n",
        "\n",
        "        results = []\n",
        "        for match in matches:\n",
        "            product_num = int(match[0])\n",
        "            question = match[1].strip()\n",
        "            answer = match[2].strip()\n",
        "            results.append({\"product\": product_num, \"question\": question, \"answer\": answer})\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        if \"429\" in str(e):\n",
        "            raise e\n",
        "        else:\n",
        "            print(f\"Error generating content: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure API keys, set parameters, and tracking progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T10:38:15.836405Z",
          "iopub.status.busy": "2025-05-14T10:38:15.835946Z",
          "iopub.status.idle": "2025-05-14T10:38:15.840334Z",
          "shell.execute_reply": "2025-05-14T10:38:15.839541Z",
          "shell.execute_reply.started": "2025-05-14T10:38:15.836384Z"
        },
        "id": "h7_RkM18V61r",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "API_KEYS = [\"AIzaSyDoibSTIUf-xAp2rlIXcKV4P99M_eqxnMw\",\"AIzaSyAWQ6A1Nf9fJb_0oWCShxHz_JDZkMjf8fA\"] \n",
        "temperature = 0.7\n",
        "\n",
        "progress_file = \"progress.txt\"\n",
        "output_csv = \"curated_vqa_dataset6.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Build the Sequential List of Image IDs for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:32.451914Z",
          "iopub.status.busy": "2025-05-14T12:33:32.451313Z",
          "iopub.status.idle": "2025-05-14T12:33:32.738654Z",
          "shell.execute_reply": "2025-05-14T12:33:32.738055Z",
          "shell.execute_reply.started": "2025-05-14T12:33:32.451890Z"
        },
        "id": "dn9gcZ_AV61s",
        "outputId": "218d431c-9bcc-4454-a48a-6bf3574fbfc1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total test images: 398170\n"
          ]
        }
      ],
      "source": [
        "\n",
        "available_image_ids = sorted(list(metadata_dict.keys()))\n",
        "test_image_ids = available_image_ids\n",
        "total_test_images = len(test_image_ids)\n",
        "print(f\"Total test images: {total_test_images}\")\n",
        "\n",
        "if not os.path.exists(output_csv):\n",
        "    pd.DataFrame(columns=[\"batch_index\", \"image_id\", \"question\", \"answer\"]).to_csv(output_csv, index=False)\n",
        "\n",
        "if os.path.exists(progress_file):\n",
        "    with open(progress_file, \"r\") as f:\n",
        "        start_index = int(f.read().strip())\n",
        "else:\n",
        "    start_index = 0\n",
        "\n",
        "batch_size = 10  \n",
        "batch_counter = start_index // batch_size  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Process the Images in Batches Until an API Limit Error Occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-14T12:33:35.822660Z",
          "iopub.status.busy": "2025-05-14T12:33:35.822403Z",
          "iopub.status.idle": "2025-05-14T12:33:45.719054Z",
          "shell.execute_reply": "2025-05-14T12:33:45.717991Z",
          "shell.execute_reply.started": "2025-05-14T12:33:35.822640Z"
        },
        "id": "UkFZ_1Q_V61s",
        "outputId": "fe09fd71-3cf6-4598-b175-73890c11ace5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/23225 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 16592: Image IDs ['71OqNnvSYcL', '71OqOFMPDOL', '71OqOcF74vL', '71OqVBp5ELL', '71OqXyCxpgL', '71OqanNJZCL', '71OqbYaORtL', '71OqcpqKrqL', '71OqiIFByZL', '71OqiytLGzL'] with API key index 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/23225 [00:04<26:29:22,  4.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 16593: Image IDs ['71Oqjvy0zyL', '71OqlhqwElL', '71OqluZrHiL', '71OqnJgEhTL', '71Oqo7X5JKL', '71OqpN8MmuL', '71OqpwWeS1L', '71OqqXj-xNL', '71OqqnRtnAL', '71OqrWkbPVL'] with API key index 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/23225 [00:09<63:32:45,  9.85s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/2981139213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mqa_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_vqa_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_metadata_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"API error encountered (likely quota exceeded): {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_31/1461322946.py\u001b[0m in \u001b[0;36mgenerate_vqa_batch\u001b[0;34m(images, metadata_texts, api_key, temperature)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mqa_pairs_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;34m\"Retrying due to {}, sleeping {:.1f}s ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_exc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sleep generator stopped yielding sleep values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(start_index, total_test_images, batch_size)):\n",
        "    current_batch = test_image_ids[i : i + batch_size]\n",
        "\n",
        "    if len(current_batch) < batch_size:\n",
        "        print(f\"Incomplete batch encountered: only {len(current_batch)} images remain. Stopping.\")\n",
        "        break\n",
        "\n",
        "    current_api_key = API_KEYS[batch_counter % len(API_KEYS)]\n",
        "\n",
        "    batch_images = []\n",
        "    batch_metadata_texts = []\n",
        "\n",
        "    for image_id in current_batch:\n",
        "        img_row = df[df['image_id'] == image_id]\n",
        "        if img_row.empty:\n",
        "            print(f\"No metadata found for image_id {image_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        relative_path = img_row['path'].values[0]\n",
        "        img_full_path = os.path.join(dataset_dir, 'abo-images-small', 'images', 'small', relative_path)\n",
        "\n",
        "        if not os.path.exists(img_full_path):\n",
        "            print(f\"File not found: {img_full_path} for image_id {image_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img_obj = Image.open(img_full_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening image {img_full_path}: {e}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        batch_images.append(img_obj)\n",
        "\n",
        "        def safe_first(value_list, default=\"Unknown\"):\n",
        "            return value_list[0] if value_list and isinstance(value_list, list) else default\n",
        "\n",
        "        meta = metadata_dict.get(image_id, {})\n",
        "        metadata_text = f\"Brand: {safe_first(meta.get('brand'))}, \" \\\n",
        "                f\"Color: {safe_first(meta.get('color'), 'N/A')}, \" \\\n",
        "                f\"Material: {safe_first(meta.get('material'), 'N/A')}, \" \\\n",
        "                f\"Item Name: {safe_first(meta.get('item_name'), '')}, \" \\\n",
        "                f\"Product Type: {meta.get('product_type', [{'value': 'N/A'}])[0].get('value', 'N/A')}\"\n",
        "\n",
        "        batch_metadata_texts.append(metadata_text)\n",
        "\n",
        "    if len(batch_images) != batch_size or len(batch_metadata_texts) != batch_size:\n",
        "        print(\"Incomplete batch (not all 10 images/metadata available). Skipping this batch.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing batch {batch_counter}: Image IDs {current_batch} with API key index {batch_counter % len(API_KEYS)}\")\n",
        "\n",
        "    try:\n",
        "        qa_results = generate_vqa_batch(batch_images, batch_metadata_texts, current_api_key, temperature)\n",
        "    except Exception as e:\n",
        "        print(f\"API error encountered (likely quota exceeded): {e}\")\n",
        "        print(\"Stopping further processing.\")\n",
        "        break \n",
        "\n",
        "    batch_results = []\n",
        "    if qa_results:\n",
        "        for qa in qa_results:\n",
        "            product_num = qa[\"product\"]\n",
        "            index_in_batch = product_num - 1\n",
        "            record = {\n",
        "                \"batch_index\": batch_counter,\n",
        "                \"image_id\": current_batch[index_in_batch],\n",
        "                \"question\": qa[\"question\"],\n",
        "                \"answer\": qa[\"answer\"]\n",
        "            }\n",
        "            batch_results.append(record)\n",
        "    else:\n",
        "        print(f\"No Q&A pairs returned for batch {batch_counter}.\")\n",
        "\n",
        "    if batch_results:\n",
        "        df_results = pd.DataFrame(batch_results)\n",
        "        df_results.to_csv(output_csv, mode='a', header=False, index=False)\n",
        "\n",
        "    batch_counter += 1\n",
        "\n",
        "    with open(progress_file, \"w\") as f:\n",
        "        f.write(str(i + batch_size))\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"Batch processing complete for the test run.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7263310,
          "sourceId": 11586516,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7311887,
          "sourceId": 11651364,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31012,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
